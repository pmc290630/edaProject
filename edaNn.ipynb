{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# King County House Pricing\n",
    "\n",
    "The stakeholder is interested in a way to predict the sales price of houses based on a variety of data. There is also to mention, that he provides a set with slightly more than 20k observations for this task. He will gladly be informed about any further insights resulting from the prior explanatory data analysis. \n",
    "\n",
    "I will be regarding real estate in King County. As this is my first data analysis for training reasons do not hesitate to comment and correct if you find mistakes.\n",
    "\n",
    "### I will cover the following topics:\n",
    "\n",
    "### Data Exploration\n",
    "+ Visualization\n",
    "+ Check correlations\n",
    "\n",
    "### Data Cleaning\n",
    "+ Deal with nan\n",
    "+ rename and drop columns\n",
    "\n",
    "### Model Building\n",
    "+ deal with categorical data\n",
    "+ train the Model\n",
    "+ optimize the Model\n",
    "\n",
    "### Present the Results\n",
    "+ Meaningful insights\n",
    "+ Prediction with OLS\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Import the libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "#import plotly.graph_objs as go"
   ]
  },
  {
   "source": [
    "### Import the data and rename"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(\"kc_house_prices/King_County_House_prices_dataset.csv\")\n",
    "for c in df0.columns: df0.rename(columns={c:c.replace(\" \",\"-\").lower()})\n",
    "df0[\"sqft_basement\"] = df0[\"sqft_basement\"].transform(lambda x: float(str(x).replace('?',\"0.0\")))\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Let's have a first look."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df0.columns: print(\"{:7s}  \\tuniques: {:.9} \\t nans: {:.9}\".format(c,str(df0[c].nunique()), str(df0[c].isna().sum() )))"
   ]
  },
  {
   "source": [
    "We notice that there are 21597 observations and 21 columns. We observe that only three columns contain nan values.\n",
    "+ waterfront: 2376\n",
    "+ view: 63\n",
    "+ yr_renovated: 3842\n",
    "\n",
    "Alrealy now we can see, that various columns only contain very few unique values. Let's have a closer look to check for categorical variables by plotting a histogram and look at the distribution. As string values are obviously categorical, we only focus on numeric values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df0.select_dtypes(include= [\"float64\", \"int64\"])\n",
    "df_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df_num[[\"price\",\"bedrooms\",\"bathrooms\", \"sqft_living\",\"sqft_lot\",\"floors\",\"waterfront\",\"view\",\"condition\",\"grade\",\"sqft_above\",\"yr_built\",\"yr_renovated\", \"sqft_living15\",\"sqft_lot15\"]]\n",
    "#df_num = df_num[df_num.price < 3e6]\n",
    "df_num.shape\n",
    "df_num = df_num[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Image generation requires the psutil package.\n\nInstall using pip:\n    $ pip install psutil\n\nInstall using conda:\n    $ conda install psutil\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-5a6f0c401b00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m#fig.to_image(width=1200, height=1200, scale=1,engine=\"kaleido\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ScatterMatrix.png\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neueFische/ds-visualisation/.venv/lib/python3.8/site-packages/plotly/basedatatypes.py\u001b[0m in \u001b[0;36mwrite_image\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3806\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3808\u001b[0m     \u001b[0;31m# Static helpers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neueFische/ds-visualisation/.venv/lib/python3.8/site-packages/plotly/io/_kaleido.py\u001b[0m in \u001b[0;36mwrite_image\u001b[0;34m(fig, file, format, scale, width, height, validate, engine)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;31m# -------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;31m# Do this first so we don't create a file if image conversion fails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     img_data = to_image(\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neueFische/ds-visualisation/.venv/lib/python3.8/site-packages/plotly/io/_kaleido.py\u001b[0m in \u001b[0;36mto_image\u001b[0;34m(fig, format, width, height, scale, validate, engine)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_orca\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_image\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mto_image_orca\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         return to_image_orca(\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neueFische/ds-visualisation/.venv/lib/python3.8/site-packages/plotly/io/_orca.py\u001b[0m in \u001b[0;36mto_image\u001b[0;34m(fig, format, width, height, scale, validate)\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;31m# Make sure orca sever is running\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;31m# -------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m     \u001b[0mensure_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m     \u001b[0;31m# Handle defaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neueFische/ds-visualisation/.venv/lib/python3.8/site-packages/plotly/io/_orca.py\u001b[0m in \u001b[0;36mensure_server\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1359\u001b[0m     \u001b[0;31m# Validate psutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpsutil\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1362\u001b[0m             \"\"\"\\\n\u001b[1;32m   1363\u001b[0m \u001b[0mImage\u001b[0m \u001b[0mgeneration\u001b[0m \u001b[0mrequires\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpsutil\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Image generation requires the psutil package.\n\nInstall using pip:\n    $ pip install psutil\n\nInstall using conda:\n    $ conda install psutil\n"
     ]
    }
   ],
   "source": [
    "fig = go.Figure(data=go.Splom(\n",
    "                  dimensions=[dict(label='price', values=df_num['price']),\n",
    "                              dict(label='bedrooms', values=df_num['bedrooms']),\n",
    "                              dict(label='bathrooms', values=df_num['bathrooms']),\n",
    "                              dict(label='sqft_living', values=df_num['sqft_living']),\n",
    "                              dict(label='sqft_lot', values=df_num['sqft_lot']),\n",
    "                              dict(label='floors', values=df_num['floors']),\n",
    "                              dict(label='waterfront', values=df_num['waterfront']),\n",
    "                              dict(label='view', values=df_num['view']),\n",
    "                              dict(label='condition', values=df_num['condition']),\n",
    "                              dict(label='grade', values=df_num['grade']),\n",
    "                              dict(label='sqft_above', values=df_num['sqft_above']),\n",
    "                              dict(label='yr_built', values=df_num['yr_built']),\n",
    "                              dict(label='yr_renovated', values=df_num['yr_renovated']),\n",
    "                              dict(label='sqft_living15', values=df_num['sqft_living15']),\n",
    "                              dict(label='sqft_lot15', values=df_num['sqft_lot15'])],\n",
    "                    marker =  dict(\n",
    "                                color=df_num['price'],\n",
    "                                size=4,\n",
    "                                colorscale='Bluered',\n",
    "                                #line=dict(width=0.5,color='rgb(230,230,230)')\n",
    "                                ),\n",
    "                    # xaxis = dict(showticklabels = False,),\n",
    "                    # yaxis = dict(showticklabels = False,),\n",
    "                    showupperhalf=False,\n",
    "                    #text=textd,\n",
    "                    showlegend=False,\n",
    "                    diagonal=dict(visible=False)))\n",
    "\n",
    "\n",
    "axisd = dict(showline=False,\n",
    "           zeroline=False,\n",
    "           ticklen=4,\n",
    "           titlefont=dict(size=9),\n",
    "           showticklabels = False,\n",
    "           tickangle = -90,\n",
    "\n",
    "           #labelangle = 45,\n",
    "           )\n",
    "\n",
    "fig.update_traces(showlegend = False,)\n",
    "\n",
    "title = \"Scatter Matrix - King County House Prices\"\n",
    "\n",
    "fig.update_layout(title = title,\n",
    "                  template = \"plotly_dark\",\n",
    "                  #dragmode='select',\n",
    "                  width=1000,\n",
    "                  xaxis1 = dict(axisd),\n",
    "                  xaxis2 = dict(axisd),\n",
    "                  xaxis3 = dict(axisd),\n",
    "                  xaxis4 = dict(axisd),\n",
    "                  xaxis5 = dict(axisd),\n",
    "                  xaxis6 = dict(axisd),\n",
    "                  xaxis7 = dict(axisd),\n",
    "                  xaxis8 = dict(axisd),\n",
    "                  xaxis9 = dict(axisd),\n",
    "                  xaxis10 = dict(axisd),\n",
    "                  xaxis11 = dict(axisd),\n",
    "                  xaxis12 = dict(axisd),\n",
    "                  xaxis13 = dict(axisd),\n",
    "                  xaxis14 = dict(axisd),\n",
    "\n",
    "                  yaxis1 = dict(axisd),\n",
    "                  yaxis2 = dict(axisd),\n",
    "                  yaxis3 = dict(axisd),\n",
    "                  yaxis4 = dict(axisd),\n",
    "                  yaxis5 = dict(axisd),\n",
    "                  yaxis6 = dict(axisd),\n",
    "                  yaxis7 = dict(axisd),\n",
    "                  yaxis8 = dict(axisd),\n",
    "                  yaxis9 = dict(axisd),\n",
    "                  yaxis10 = dict(axisd),\n",
    "                  yaxis11 = dict(axisd),\n",
    "                  yaxis12 = dict(axisd),\n",
    "                  yaxis13 = dict(axisd),\n",
    "                  yaxis14 = dict(axisd),\n",
    "                  yaxis15 = dict(axisd),\n",
    "\n",
    "                  height=1000,\n",
    "                  hovermode='closest',\n",
    "                  xaxis = dict(showticklabels = False,),\n",
    "                  yaxis = dict(showticklabels = False,scaleratio = 0.5,),\n",
    "                  showlegend=False,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(tickangle = 45,\n",
    ")\n",
    "#from IPython.display import Image\n",
    "import plotly.io as pio\n",
    "# pio.kaleido.scope.default_format = \"png\"\n",
    "# pio.kaleido.scope.default_height = 1200\n",
    "# pio.kaleido.scope.default_width = 1200\n",
    "\n",
    "#fig.to_image(width=1200, height=1200, scale=1,engine=\"kaleido\")\n",
    "\n",
    "fig.write_image(\"ScatterMatrix.png\",width=1200, height=1200)\n",
    "\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# fig = px.scatter_matrix(\n",
    "#     df_num.iloc[:,:], \n",
    "#     template=\"plotly_dark\",\n",
    "#     color = \"price\",\n",
    "#     color_continuous_scale=\"Bluered\")#Plotly3\n",
    "# fig.update_traces(\n",
    "#     marker = dict(\n",
    "#         line_width = 0.1,\n",
    "#         #color  = \"red\",\n",
    "#         #showlegend = False,\n",
    "#         opacity = 1,\n",
    "#     ),\n",
    "#     marker_symbol = \"circle\",\n",
    "#     marker_size = 4\n",
    "# )\n",
    "# fig.update_layout(\n",
    "#     title = \"Scatter Matrix - King County House Prices\",\n",
    "#     width = 1200,\n",
    "#     height = 1200,\n",
    "#     xaxis = dict(\n",
    "#         showticklabels = False,\n",
    "#     ),\n",
    "#     yaxis = dict(\n",
    "#         showticklabels = False,\n",
    "#     ),\n",
    "#     showlegend=False,\n",
    "# )\n",
    "\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = make_subplots(rows=5, cols=3)\n",
    "\n",
    "# trace0 = go.Histogram(x=df_num[\"price\"], nbinsx=50)\n",
    "# trace1 = go.Histogram(x=df_num[\"bedrooms\"], nbinsx=50)\n",
    "# trace2 = go.Histogram(x=df_num[\"bathrooms\"], nbinsx=50)\n",
    "# trace3 = go.Histogram(x=df_num[\"sqft_living\"], nbinsx=50)\n",
    "# trace4 = go.Histogram(x=df_num[\"sqft_lot\"], nbinsx=50)\n",
    "\n",
    "# trace5 = go.Histogram(x=df_num[\"floors\"], nbinsx=50)\n",
    "# trace6 = go.Histogram(x=df_num[\"waterfront\"], nbinsx=50)\n",
    "# trace7 = go.Histogram(x=df_num[\"view\"], nbinsx=50)\n",
    "# trace8 = go.Histogram(x=df_num[\"condition\"], nbinsx=50)\n",
    "# trace9 = go.Histogram(x=df_num[\"grade\"], nbinsx=50)\n",
    "\n",
    "# trace10 = go.Histogram(x=df_num[\"sqft_above\"], nbinsx=50)\n",
    "# trace11 = go.Histogram(x=df_num[\"yr_built\"], nbinsx=50)\n",
    "# trace12 = go.Histogram(x=df_num[\"yr_renovated\"], nbinsx=50)\n",
    "# trace13 = go.Histogram(x=df_num[\"sqft_living15\"], nbinsx=50)\n",
    "# trace14 = go.Histogram(x=df_num[\"sqft_lot15\"], nbinsx=50)\n",
    "\n",
    "# fig.append_trace(trace0, 1, 1)\n",
    "# fig.append_trace(trace1, 2, 2)\n",
    "# fig.append_trace(trace2, 3, 3)\n",
    "# fig.append_trace(trace3, 4, 1)\n",
    "# fig.append_trace(trace4, 5, 2)\n",
    "\n",
    "# fig.append_trace(trace5, 1, 3)\n",
    "# fig.append_trace(trace6, 2, 1)\n",
    "# fig.append_trace(trace7, 3, 2)\n",
    "# fig.append_trace(trace8, 4, 3)\n",
    "# fig.append_trace(trace9, 5, 1)\n",
    "\n",
    "# fig.append_trace(trace10, 1, 2)\n",
    "# fig.append_trace(trace11, 2, 3)\n",
    "# fig.append_trace(trace12, 3, 1)\n",
    "# fig.append_trace(trace13, 4, 2)\n",
    "# fig.append_trace(trace14, 5, 3)\n",
    "\n",
    "# fig.update_layout(\n",
    "#     template = \"plotly_dark\",\n",
    "#     width=1000,\n",
    "#     height=1000,\n",
    "#     )\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "source": [
    "Regarding the histogram plot helps us to profound our ideas to treat certain variables as categorical."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = df_num.hist(figsize= (16,20), bins= 50, xlabelsize= 8, ylabelsize= 8);\n",
    "fig"
   ]
  },
  {
   "source": [
    "The scatter matrix plot and the histogram make the categorical character of a couple of variables together with the unique() plot from above clear. The variables\n",
    "+ date\n",
    "+ floors\n",
    "+ bathrooms\n",
    "+ bedrooms\n",
    "+ waterfront\n",
    "+ view\n",
    "+ condition\n",
    "+ grade\n",
    "+ yr_built\n",
    "+ yr_renovated\n",
    "+ zipcode\n",
    "\n",
    "have a categorical character.\n",
    "\n",
    "### Let's have a look at the distribution of the price."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(df0, x = \"price\", template=\"plotly_dark\",orientation=\"h\", points = \"all\", title =\"price - boxplot\")\n",
    "fig.update_traces(\n",
    "    marker = dict(\n",
    "        line_width = 0.1,\n",
    "        opacity = 1,\n",
    "    ),\n",
    "    marker_symbol = \"circle\",\n",
    "    marker_size = .5\n",
    ")\n",
    "# fig.write_image(\"priceBoxplot.png\",width=1200, height=1200)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df0, x= \"price\", template=\"plotly_dark\", title = \"price - histogram\")\n",
    "fig.update_traces(\n",
    ")\n",
    "# fig.write_image(\"priceHistogram.png\",width=1200, height=1200)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = np.log(df0[['price']])\n",
    "px.histogram(df_log, x = \"price\", template= \"plotly_dark\" )   "
   ]
  },
  {
   "source": [
    "For certain operatins a normally distributed dataset is needed. Via log this is possible."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The median is {:}.\".format(df0[\"price\"].median()))\n",
    "print(\"The skewness is {:}.\".format(round(df0.price.skew(),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0[[\"price\"]].describe().round(2)"
   ]
  },
  {
   "source": [
    "The price data is strongly right skewed and unimodal. The median is a lot lower than the mean, what supports the strong right skewness, that we observe in the histogram, boxplot."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Correlation\n",
    "\n",
    "Let's have a look at the $R^2$ correlation between all variables."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = df0.corr()\n",
    "dfr2 = dfr.transform(lambda x: x**2)\n",
    "\n",
    "sns.set(rc={\"figure.figsize\":(16,16)})\n",
    "\n",
    "#fig, ax = pyplot.subplot(figsize = 10.0 ,10.0)\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    dfr2,\n",
    "    vmin = -1, vmax= +1, center = 0,\n",
    "    cmap = sns.diverging_palette(20, 220, n=200),\n",
    "    square= True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = dfr2[\"price\"].sort_values(ascending=False)[1:7]\n",
    "out = \"The top correlations for price are:\\n\"\n",
    "for i, e in zip(list(s.index),list(s.values)):\n",
    "    out += \"\\t {:7s} \\t {}\\n\".format(i, round(e,5)) \n",
    "print(out)"
   ]
  },
  {
   "source": [
    "Apart from the obvious and price related relations like sqft_above and sqft_living, that are dependent on each other, thus do not deliver great new insights, we notice:\n",
    "\n",
    "+ the higher the grade, the larger sqft_living15, meaning that living space of neighbours increases\n",
    "+ the larger sqft_lot, the lager sqft_lot15, meaning the larger the lot, the lot size of neighbours increases.\n",
    "\n",
    "Apart obvious things like an increasing number of bathrooms and bedrooms shows up depending on sqft_living and sqft_above."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:}% of all sales prices are below 1000000.\".format(round(df0[df0[\"price\"] < 1e6][\"price\"].count() / df0.price.count()*100),1))"
   ]
  },
  {
   "source": [
    "## Seasonal influence on housing prices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dates = df0.copy()\n",
    "df_dates[\"date\"] = df_dates[\"date\"].transform(lambda x: pd.to_datetime(x).month)\n",
    "df_dates = df_dates[[\"date\", \"price\"]]\n",
    "df_dates2 = df_dates[[\"date\", \"price\"]]\n",
    "\n",
    "df_dates = df_dates.groupby(\"date\").mean().reset_index().round(2)\n",
    "df_dates2 = df_dates2.groupby(\"date\").median().reset_index().round(2)\n",
    "\n",
    "df_dates = df_dates.join(df_dates2[\"price\"], rsuffix=\"2\")\n",
    "df_dates.rename(columns={\"price\":\"price_mean\", \"price2\":\"price_median\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_dates, x='date', y=['price_mean','price_median'], labels={'x':'Date', 'y':'Price'},\n",
    "       title='Seasonal Price Mean vs Median',template=\"plotly_dark\")\n",
    "\n",
    "# fig.write_image(\"SeasonMeanMedianPrice.png\",width=1200, height=1200)\n",
    "fig.show()"
   ]
  },
  {
   "source": [
    "We notice that the mean of housing sales prices are seasonally influenced. From April to June the highest prices can be achieved. This counts as well for the mean as for the median. The winter is the best time to buy houses and spring to early summer is the best time sell. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Geographical analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfzipCode = df0[[\"price\",\"zipcode\"]].sort_values(\"price\",ascending=False)\n",
    "\n",
    "dfzipCode[\"zipcode\"] = dfzipCode[\"zipcode\"].astype(\"category\")\n",
    "\n",
    "dfzipCodeCount = dfzipCode.groupby(\"zipcode\").count().reset_index()\n",
    "dfzipCodeSum = dfzipCode.groupby(\"zipcode\").sum().reset_index()\n",
    "dfzipCodeMedian = dfzipCode.groupby(\"zipcode\").median().reset_index()\n",
    "\n",
    "dfzipCodeCount.sort_values(\"price\", ascending=False, inplace=True)\n",
    "\n",
    "dfzipCode = dfzipCodeCount.merge(dfzipCodeSum, on = \"zipcode\", suffixes=[\"_count\", \"_sum\"])\n",
    "dfzipCode = dfzipCode.merge(dfzipCodeMedian, on = \"zipcode\", suffixes=[\"\",\"_median\"])\n",
    "dfzipCode.rename(columns={\"price\": \"price_median\", \"price_count\":\"counts\"}, inplace=True)\n",
    "\n",
    "dfzipCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(dfzipCode, x=\"price_median\", y=\"counts\", color=\"zipcode\",\n",
    "                 size='price_sum', template= \"plotly_dark\", width = 1000, height = 600)\n",
    "\n",
    "# fig.write_image(\"priceZipcodeCountsScatter.png\",width=1200, height=1200)\n",
    "fig.show()"
   ]
  },
  {
   "source": [
    "Interestingly there is a slight trend where the median of sales prices rises as the number of sales increase in a zipcode area. This is counter intuitive to the assumption that people would buy more houses, where prices are lower, but the data shows a contrary trend. Maybe the higher prices represent better neighborhoods, that attract more "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Regression Analysis\n",
    "\n",
    "We must now chose what data to treat categorically. One very important thing to mention is, that predictions on categorical can only be made an brought to use, if the input meets the exact structure of the categories. This implies to take a deep thought into the future intention of predictions.\n",
    "\n",
    "In our case, we assume to make future house price predictions based on our historical data. This means, that categories can only be chosen for variables, that we assume to be input in the same format as our chosen categories provide options. \n",
    "\n",
    "Generally speaking, what variable will be one-hoted, and what variables will stay numeric or will be taken out of our scope of consideration as a feature in total.\n",
    "\n",
    "+ date: It makes no sense to add the exact day of a date to the prediction model, because future predictions will be impossible with the influence of passed dates in this way. Instead the date will be transformed to month to bring seasonal influence into the prediction, eliminating the day and the year.\n",
    "+ floors: We are provided with 6 unique values: $[1.0, 2.0, 1.5, 3.0, 2.5, 3.5]$. As we are missing $1.5$ and this is a possible value in the future, this variable will not let us predict prices for a values of $1.5$. But because we didn't have this value occuring even once in the large set, we will decide, that this event is too rare and treat the floors categorically.\n",
    "+ bathrooms: $[1.0, 2.25, 3.0, 2.0, 4.5, 1.5, 2.5, 1.75, 2.75, 3.25, 4.0, 3.5, 0.75, 4.75, 5.0, 4.25, 3.75, 1.25, 5.25, 6.0, 0.5 , 5.5 ,6.75, 5.75, 8.0, 7.5, 7.75, 6.25, 6.5]$ The options for bathrooms seem large enough to treatd categorically.\n",
    "+ bedrooms: $[3, 2, 4, 5, 1, 6, 7, 8, 9, 11, 10, 33]$ We find values up to $11$ and one outlier for 33. As $93%$ of all prices have been less than a million and the current choice possibility for bathrooms seems reasonably sufficient to be used as a category. \n",
    "+ waterfront: This dataset holds $2376$ nan values. It adds almost no value to value to the regression model. We will drop this column for the regression.\n",
    "+ view: This column holds $63$ nan values. The value for the regression is good and therefore will be respected as a categorical variable.\n",
    "+ condition: $[3, 5, 4, 1, 2]$ These values clearly state categories.\n",
    "+ grade: $[7, 6, 8, 11, 9, 5, 10, 12, 4, 3, 13]$ Grades are clearly categorical and provide good results for the regression as also they correlate second best with price.\n",
    "+ yr_built: Catogorizing data almost always improves the $R^2$ value and therefore tempts to catogorize the yr_built. Doing so will make future prediction impossible and therefore will be treated numerically.\n",
    "+ yr_renovated: Here we find $3842$ nan values. This variable also adds very little value to our regression analysis. Using it we would sacrifice almost $4000$ observations and thus will drop this column.\n",
    "+ zipcode: There are $70$ different zipcodes in the dataset, and provide good information about housing prices. This variablw will be treated categorically."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df0.copy()\n",
    "drop_cols = [\"id\", \"waterfront\", \"lat\", \"long\", \"yr_renovated\"]\n",
    "num_cols = [\"sqft_living\",\"sqft_lot\",\"sqft_above\",\"sqft_basement\",\"yr_built\",\"sqft_living15\",\"sqft_lot15\"]\n",
    "cats_cols = [\"date\",\"bedrooms\",\"bathrooms\",\"floors\",\"view\",\"condition\",\"grade\",\"zipcode\"]\n",
    "\n",
    "df_reg.drop(drop_cols, axis = 1, inplace= True)\n",
    "df_reg.dropna(inplace= True)\n",
    "df_reg[\"date\"] = df_reg[\"date\"].transform(lambda x: pd.to_datetime(x).month)\n",
    "df_reg"
   ]
  },
  {
   "source": [
    "#create string for OLS\n",
    "s = \"\"\n",
    "for c in num_cols: s += c + \"+\"\n",
    "for c in cats_cols: s += \"C({:})+\".format(c)\n",
    "s=s[:-1]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(formula=\"price~\"+s, data=df_reg).fit()\n",
    "\n",
    "results = model.summary()\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'KingCountyRegressionModel.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}